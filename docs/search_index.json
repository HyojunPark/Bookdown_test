[["bias-assessment.html", "Chapter 2 Bias assessment 2.1 Bias due to omitted confounders 2.2 Overadjustment bias 2.3 Total effect 2.4 Overadjustment 2.5 Logistic models", " Chapter 2 Bias assessment Available at https://rpubs.com/Hyojun/bias 2.1 Bias due to omitted confounders \\[y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_2 + \\dots + \\epsilon_i; \\;\\; for \\;\\; i=1, \\dots, n\\] where the errors \\(\\epsilon_i \\sim N(0, \\sigma^2)\\) with independent and identically distributed (i.i.d.) Let’s assume the following association is true (i.e., gold standard) without any selection bias, measurement bias, and other unmeasured confoundings. N &lt;- 100000 C &lt;- rnorm(N) X &lt;- .5 * C + rnorm(N) Y &lt;- .3 * C + .4 * X + rnorm(N) 2.1.1 Gold standard With the correct model specification (i.e., \\(C\\) as a confounder), we get an unbiased estimate of \\(X\\) on \\(Y\\). # Gold standard glm.unbiased &lt;- glm(Y~X + C, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X + C, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.2001 -0.6727 0.0041 0.6762 4.5112 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.001067 0.003171 0.337 0.736 ## X 0.403637 0.003173 127.201 &lt;2e-16 *** ## C 0.300055 0.003557 84.362 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 1.005701) ## ## Null deviance: 141965 on 99999 degrees of freedom ## Residual deviance: 100567 on 99997 degrees of freedom ## AIC: 284361 ## ## Number of Fisher Scoring iterations: 2 2.1.2 Misspecified model: a confounder, \\(C\\), was omitted from the model By omitting \\(C\\), the estimate of \\(X\\) was biased either “away from” or “towards to” the null # C was omitted glm.unbiased &lt;- glm(Y~X, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.4468 -0.6962 0.0041 0.7020 4.9310 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0004783 0.0032822 0.146 0.884 ## X 0.5235183 0.0029365 178.281 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 1.077269) ## ## Null deviance: 141965 on 99999 degrees of freedom ## Residual deviance: 107725 on 99998 degrees of freedom ## AIC: 291235 ## ## Number of Fisher Scoring iterations: 2 2.1.3 Bias “away from” or “towards to” the null? N &lt;- 100000 C &lt;- rnorm(N) X &lt;- -.5 * C + rnorm(N) Y &lt;- -.3 * C + .4 * X + rnorm(N) # C was omitted glm.unbiased &lt;- glm(Y~X + C, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X + C, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.5069 -0.6734 -0.0005 0.6773 4.0939 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.001220 0.003158 0.386 0.699 ## X 0.400824 0.003160 126.831 &lt;2e-16 *** ## C -0.299071 0.003533 -84.663 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.9975295) ## ## Null deviance: 141008 on 99999 degrees of freedom ## Residual deviance: 99750 on 99997 degrees of freedom ## AIC: 283545 ## ## Number of Fisher Scoring iterations: 2 glm.unbiased &lt;- glm(Y~X, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.9440 -0.6965 -0.0019 0.6962 3.9948 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.003258 0.003270 0.997 0.319 ## X 0.521531 0.002920 178.622 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 1.069022) ## ## Null deviance: 141008 on 99999 degrees of freedom ## Residual deviance: 106900 on 99998 degrees of freedom ## AIC: 290466 ## ## Number of Fisher Scoring iterations: 2 2.1.4 A \\(C\\) is not a confounder on \\(X\\) and \\(Y\\) N &lt;- 100000 C &lt;- rnorm(N) X &lt;- rnorm(N) Y &lt;- .4 * X + rnorm(N) 2.1.5 Correct model specification: Without \\(C\\) glm.unbiased &lt;- glm(Y~X, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.1359 -0.6732 -0.0018 0.6729 4.5065 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0004384 0.0031657 0.138 0.89 ## X 0.3977515 0.0031709 125.438 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 1.002152) ## ## Null deviance: 115982 on 99999 degrees of freedom ## Residual deviance: 100213 on 99998 degrees of freedom ## AIC: 284007 ## ## Number of Fisher Scoring iterations: 2 2.1.6 Misspecified model with \\(C\\) glm.unbiased &lt;- glm(Y~X + C, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X + C, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.1341 -0.6734 -0.0018 0.6729 4.5079 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0004366 0.0031657 0.138 0.890 ## X 0.3977495 0.0031709 125.437 &lt;2e-16 *** ## C 0.0014321 0.0031670 0.452 0.651 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 1.00216) ## ## Null deviance: 115982 on 99999 degrees of freedom ## Residual deviance: 100213 on 99997 degrees of freedom ## AIC: 284008 ## ## Number of Fisher Scoring iterations: 2 2.1.7 A \\(C\\) is a colloder on \\(X\\) and \\(Y\\) N &lt;- 100000 X &lt;- rnorm(N) Y &lt;- .7 * X + rnorm(N) C &lt;- 1.2 * X + .6 * Y + rnorm(N) 2.1.8 Correct model specification: Without \\(C\\) glm.unbiased &lt;- glm(Y~X, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.0624 -0.6756 0.0021 0.6787 4.3708 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.001463 0.003161 0.463 0.643 ## X 0.700049 0.003161 221.433 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.99939) ## ## Null deviance: 148940 on 99999 degrees of freedom ## Residual deviance: 99937 on 99998 degrees of freedom ## AIC: 283731 ## ## Number of Fisher Scoring iterations: 2 2.1.9 Misspecified model with \\(C\\) This is one of examples of selection bias. For example, let’s say, \\(X\\) is Education, \\(Y\\) is income, and \\(C\\) is social welfare program. People at lower education (i.e., high risk group in terms of exposure) and lower income (i.e., higher risk group in terms of outcome) are more likely to register social welfare program. If survey was conducted based on the registered social welfare program, the “estimated” association from this “disproportionally selected” respondents are likely biased. glm.unbiased &lt;- glm(Y~X + C, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X + C, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -3.7217 -0.5788 -0.0002 0.5825 3.7354 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.001837 0.002713 0.677 0.49825 ## X -0.014316 0.004649 -3.079 0.00208 ** ## C 0.440719 0.002329 189.211 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.7359254) ## ## Null deviance: 148940 on 99999 degrees of freedom ## Residual deviance: 73590 on 99997 degrees of freedom ## AIC: 253130 ## ## Number of Fisher Scoring iterations: 2 2.2 Overadjustment bias Please note that this is not a comprehensive example; only reflect one aspect of potential overadjustement bias. Let’s assume a model with \\(M\\) as a mediator. N &lt;- 100000 X &lt;- rnorm(N) M &lt;- .5 * X + rnorm(N) Y &lt;- .3 * X + .4 * M + rnorm(N) 2.3 Total effect glm.unbiased &lt;- glm(Y~X, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.6774 -0.7253 0.0020 0.7314 4.6742 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.001494 0.003414 -0.438 0.662 ## X 0.507338 0.003404 149.044 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 1.165675) ## ## Null deviance: 142459 on 99999 degrees of freedom ## Residual deviance: 116565 on 99998 degrees of freedom ## AIC: 299122 ## ## Number of Fisher Scoring iterations: 2 2.4 Overadjustment glm.unbiased &lt;- glm(Y~X + M, family=&quot;gaussian&quot;) summary(glm.unbiased) ## ## Call: ## glm(formula = Y ~ X + M, family = &quot;gaussian&quot;) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.5165 -0.6733 -0.0002 0.6788 4.7492 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.003411 0.003164 1.078 0.281 ## X 0.303497 0.003533 85.911 &lt;2e-16 *** ## M 0.403739 0.003149 128.198 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 1.001147) ## ## Null deviance: 142459 on 99999 degrees of freedom ## Residual deviance: 100112 on 99997 degrees of freedom ## AIC: 283907 ## ## Number of Fisher Scoring iterations: 2 2.5 Logistic models 2.5.1 Sex as a Confounder, \\(C\\) MYY &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;Yes&quot;, Cancer = 1, freq = 5 ) MYN &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;Yes&quot;, Cancer = 0, freq = 8 ) MNY &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;No&quot;, Cancer = 1, freq = 45 ) MNN &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;No&quot;, Cancer = 0, freq = 72 ) FYY &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;Yes&quot;, Cancer = 1, freq = 25 ) FYN &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;Yes&quot;, Cancer = 0, freq = 10 ) FNY &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;No&quot;, Cancer = 1, freq = 25 ) FNN &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;No&quot;, Cancer = 0, freq = 10 ) Ex_confounder &lt;- rbind(MYY, MYN, MNY, MNN, FYY, FYN, FNY, FNN) Convert Freq table to raw data library(tidyr) raw_confounder &lt;- Ex_confounder %&gt;% uncount(freq) glm.unbiased &lt;- glm(Cancer ~ Smoking , family=binomial(link = &quot;logit&quot;), data=raw_confounder) summary(glm.unbiased) ## ## Call: ## glm(formula = Cancer ~ Smoking, family = binomial(link = &quot;logit&quot;), ## data = raw_confounder) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.40059 -1.11100 -0.07073 1.24530 1.24530 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.1582 0.1627 -0.972 0.3309 ## SmokingYes 0.6690 0.3397 1.970 0.0489 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 277.26 on 199 degrees of freedom ## Residual deviance: 273.28 on 198 degrees of freedom ## AIC: 277.28 ## ## Number of Fisher Scoring iterations: 4 Full model: glm_logit &lt;- glm(Cancer ~ Smoking + Sex , family=binomial(link = &quot;logit&quot;), data=raw_confounder) glm_logit ## ## Call: glm(formula = Cancer ~ Smoking + Sex, family = binomial(link = &quot;logit&quot;), ## data = raw_confounder) ## ## Coefficients: ## (Intercept) SmokingYes SexMale ## 9.163e-01 4.266e-15 -1.386e+00 ## ## Degrees of Freedom: 199 Total (i.e. Null); 197 Residual ## Null Deviance: 277.3 ## Residual Deviance: 257 AIC: 263 Stratified models ## For males raw_confounder_M &lt;- raw_confounder[ which(raw_confounder$Sex==&#39;Male&#39;), ] glm_logit_m &lt;- glm(Cancer ~ Smoking , family=binomial(link = &quot;logit&quot;), data=raw_confounder_M) glm_logit_m ## ## Call: glm(formula = Cancer ~ Smoking, family = binomial(link = &quot;logit&quot;), ## data = raw_confounder_M) ## ## Coefficients: ## (Intercept) SmokingYes ## -4.700e-01 6.672e-16 ## ## Degrees of Freedom: 129 Total (i.e. Null); 128 Residual ## Null Deviance: 173.2 ## Residual Deviance: 173.2 AIC: 177.2 # For females raw_confounder_F &lt;- raw_confounder[ which(raw_confounder$Sex==&#39;Female&#39;), ] glm_logit_f &lt;- glm(Cancer ~ Smoking , family=binomial(link = &quot;logit&quot;), data=raw_confounder_F) glm_logit_f ## ## Call: glm(formula = Cancer ~ Smoking, family = binomial(link = &quot;logit&quot;), ## data = raw_confounder_F) ## ## Coefficients: ## (Intercept) SmokingYes ## 9.163e-01 9.400e-16 ## ## Degrees of Freedom: 69 Total (i.e. Null); 68 Residual ## Null Deviance: 83.76 ## Residual Deviance: 83.76 AIC: 87.76 2.5.2 Sex as a Moderator, \\(M\\) MYY &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;Yes&quot;, Cancer = 1, freq = 5 ) MYN &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;Yes&quot;, Cancer = 0, freq = 4 ) MNY &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;No&quot;, Cancer = 1, freq = 45 ) MNN &lt;- data.frame(Sex = &quot;Male&quot;, Smoking = &quot;No&quot;, Cancer = 0, freq = 68 ) FYY &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;Yes&quot;, Cancer = 1, freq = 25 ) FYN &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;Yes&quot;, Cancer = 0, freq = 14 ) FNY &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;No&quot;, Cancer = 1, freq = 25 ) FNN &lt;- data.frame(Sex = &quot;Female&quot;, Smoking = &quot;No&quot;, Cancer = 0, freq = 14 ) Ex_moderator &lt;- rbind(MYY, MYN, MNY, MNN, FYY, FYN, FNY, FNN) Convert Freq table to raw data library(tidyr) raw_moderator &lt;- Ex_moderator %&gt;% uncount(freq) Full model: glm_logit &lt;- glm(Cancer ~ Smoking , family=binomial(link = &quot;logit&quot;), data=raw_moderator) glm_logit ## ## Call: glm(formula = Cancer ~ Smoking, family = binomial(link = &quot;logit&quot;), ## data = raw_moderator) ## ## Coefficients: ## (Intercept) SmokingYes ## -0.1582 0.6690 ## ## Degrees of Freedom: 199 Total (i.e. Null); 198 Residual ## Null Deviance: 277.3 ## Residual Deviance: 273.3 AIC: 277.3 Stratified models ## For males raw_moderator_M &lt;- raw_moderator[ which(raw_moderator$Sex==&#39;Male&#39;), ] glm_logit_m &lt;- glm(Cancer ~ Smoking , family=binomial(link = &quot;logit&quot;), data=raw_moderator_M) glm_logit_m ## ## Call: glm(formula = Cancer ~ Smoking, family = binomial(link = &quot;logit&quot;), ## data = raw_moderator_M) ## ## Coefficients: ## (Intercept) SmokingYes ## -0.4128 0.6360 ## ## Degrees of Freedom: 121 Total (i.e. Null); 120 Residual ## Null Deviance: 165.1 ## Residual Deviance: 164.3 AIC: 168.3 # For females raw_moderator_F &lt;- raw_moderator[ which(raw_moderator$Sex==&#39;Female&#39;), ] glm_logit_f &lt;- glm(Cancer ~ Smoking , family=binomial(link = &quot;logit&quot;), data=raw_moderator_F) glm_logit_f ## ## Call: glm(formula = Cancer ~ Smoking, family = binomial(link = &quot;logit&quot;), ## data = raw_moderator_F) ## ## Coefficients: ## (Intercept) SmokingYes ## 5.798e-01 -2.621e-16 ## ## Degrees of Freedom: 77 Total (i.e. Null); 76 Residual ## Null Deviance: 101.8 ## Residual Deviance: 101.8 AIC: 105.8 "]]
